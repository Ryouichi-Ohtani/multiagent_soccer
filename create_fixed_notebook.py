#!/usr/bin/env python3
"""
Create a fixed version of the integrated Google Colab notebook
with all import statements properly handled
"""

import json
import re

def remove_internal_imports(code):
    """Remove imports from internal modules"""
    internal_modules = [
        'config', 'physics', 'spaces', 'rewards', 
        'renderer', 'soccer_env', 'agents', 'trainers', 
        'test_environment'
    ]
    
    lines = code.split('\n')
    filtered_lines = []
    
    for line in lines:
        # Check if this is an import from internal modules
        is_internal_import = False
        for module in internal_modules:
            if re.search(f'from {module} import', line) or re.search(f'^import {module}', line.strip()):
                is_internal_import = True
                break
        
        # Skip internal imports (comment them out)
        if not is_internal_import:
            filtered_lines.append(line)
    
    return '\n'.join(filtered_lines)

def create_fixed_integrated_notebook():
    """Create the complete integrated notebook with fixed imports"""
    
    # Read all Python files
    python_files = {}
    file_names = ['config.py', 'physics.py', 'spaces.py', 'rewards.py', 
                  'renderer.py', 'soccer_env.py', 'agents.py', 'trainers.py', 
                  'test_environment.py']
    
    for file_name in file_names:
        with open(f'/home/user/webapp/{file_name}', 'r') as f:
            # Remove internal imports from each file
            python_files[file_name] = remove_internal_imports(f.read())
    
    # Create notebook structure
    notebook = {
        "nbformat": 4,
        "nbformat_minor": 0,
        "metadata": {
            "colab": {
                "provenance": [],
                "gpuType": "T4",
                "collapsed_sections": []
            },
            "kernelspec": {
                "name": "python3",
                "display_name": "Python 3"
            },
            "language_info": {
                "name": "python"
            },
            "accelerator": "GPU"
        },
        "cells": []
    }
    
    # Add title and overview
    notebook['cells'].append({
        "cell_type": "markdown",
        "metadata": {"id": "title_cell"},
        "source": [
            "# ğŸ® Multi-Agent Soccer Game with Deep Reinforcement Learning\n",
            "## Google Colab å®Œå…¨çµ±åˆç‰ˆ (ä¿®æ­£ç‰ˆ)\n\n",
            "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯æ·±å±¤å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ãŸãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚µãƒƒã‚«ãƒ¼ã‚²ãƒ¼ãƒ ã®å®Œå…¨çµ±åˆç‰ˆã§ã™ã€‚\n",
            "ã™ã¹ã¦ã®å¿…è¦ãªã‚³ãƒ¼ãƒ‰ãŒå˜ä¸€ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å†…ã«å«ã¾ã‚Œã¦ãŠã‚Šã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ãŒä¿®æ­£ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n",
            "### ğŸ“‹ å®Ÿè£…å†…å®¹\n",
            "- **ç’°å¢ƒ**: 2v2ã‚µãƒƒã‚«ãƒ¼ã‚²ãƒ¼ãƒ ï¼ˆPettingZooäº’æ›ï¼‰\n",
            "- **ç‰©ç†ã‚¨ãƒ³ã‚¸ãƒ³**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãªè¡çªæ¤œå‡ºã¨ãƒœãƒ¼ãƒ«ç‰©ç†\n",
            "- **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**: Random, DQN, MADDPG\n",
            "- **è¦³æ¸¬ç©ºé–“**: 28æ¬¡å…ƒï¼ˆãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ä½ç½®ã€ãƒœãƒ¼ãƒ«çŠ¶æ…‹ã€ã‚²ãƒ¼ãƒ æƒ…å ±ï¼‰\n",
            "- **è¡Œå‹•ç©ºé–“**: 5æ¬¡å…ƒé€£ç¶šè¡Œå‹•ï¼ˆç§»å‹•+ã‚­ãƒƒã‚¯ï¼‰\n",
            "- **å ±é…¬ã‚·ã‚¹ãƒ†ãƒ **: å¤šç›®çš„å ±é…¬é–¢æ•°\n\n",
            "### âš ï¸ å®Ÿè¡Œã®æ³¨æ„äº‹é …\n",
            "1. **ä¸Šã‹ã‚‰é †ç•ªã«å®Ÿè¡Œã—ã¦ãã ã•ã„** - å„ã‚»ãƒ«ãŒå‰ã®ã‚»ãƒ«ã§å®šç¾©ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ã«ä¾å­˜ã—ã¦ã„ã¾ã™\n",
            "2. **GPUä½¿ç”¨æ¨å¥¨** - Runtime â†’ Change runtime type â†’ GPU\n",
            "3. **ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ã‚»ãƒ«ã‚’å®Ÿè¡Œ** - ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã¨å¾Œç¶šã®ã‚»ãƒ«ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã™\n\n",
            "### ğŸ“Š å®Ÿè£…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ\n",
            "è©³ç´°ãªå®Ÿè£…å†…å®¹ã¯ã€Œãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚µãƒƒã‚«ãƒ¼ã‚²ãƒ¼ãƒ å®Ÿè£…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ.pdfã€ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚"
        ]
    })
    
    # Add dependency installation
    notebook['cells'].append({
        "cell_type": "markdown",
        "metadata": {"id": "install_header"},
        "source": ["## ğŸ“¦ 1. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"]
    })
    
    notebook['cells'].append({
        "cell_type": "code",
        "metadata": {"id": "install_deps", "cellView": "form"},
        "execution_count": None,
        "outputs": [],
        "source": [
            "#@title ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« (ã‚¯ãƒªãƒƒã‚¯ã—ã¦å®Ÿè¡Œ)\n",
            "# Google Colabç”¨ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
            "!pip install -q gymnasium\n",
            "!pip install -q pettingzoo\n",
            "!pip install -q pygame\n",
            "!pip install -q torch torchvision\n",
            "!pip install -q matplotlib seaborn\n",
            "!pip install -q numpy\n",
            "!pip install -q opencv-python\n\n",
            "print(\"âœ… All dependencies installed successfully!\")"
        ]
    })
    
    # Add imports
    notebook['cells'].append({
        "cell_type": "markdown",
        "metadata": {"id": "import_header"},
        "source": ["## ğŸ”§ 2. åŸºæœ¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"]
    })
    
    notebook['cells'].append({
        "cell_type": "code",
        "metadata": {"id": "imports", "cellView": "form"},
        "execution_count": None,
        "outputs": [],
        "source": [
            "#@title åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (ã‚¯ãƒªãƒƒã‚¯ã—ã¦å®Ÿè¡Œ)\n",
            "# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
            "import numpy as np\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.optim as optim\n",
            "import torch.nn.functional as F\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "from typing import Dict, List, Tuple, Optional, Any, Union\n",
            "import json\n",
            "from collections import defaultdict, deque\n",
            "import random\n",
            "from dataclasses import dataclass\n",
            "from abc import ABC, abstractmethod\n",
            "import time\n",
            "import os\n\n",
            "# Gymnasium and PettingZoo\n",
            "import gymnasium as gym\n",
            "from gymnasium import spaces\n",
            "from pettingzoo import AECEnv\n",
            "from pettingzoo.utils import agent_selector, wrappers\n\n",
            "# Pygame (optional for rendering)\n",
            "try:\n",
            "    import pygame\n",
            "    PYGAME_AVAILABLE = True\n",
            "except ImportError:\n",
            "    PYGAME_AVAILABLE = False\n",
            "    print(\"âš ï¸ Pygame not available. Rendering disabled.\")\n\n",
            "# Set random seeds\n",
            "np.random.seed(42)\n",
            "torch.manual_seed(42)\n",
            "if torch.cuda.is_available():\n",
            "    torch.cuda.manual_seed(42)\n\n",
            "# Set matplotlib style\n",
            "plt.style.use('seaborn-v0_8-darkgrid')\n",
            "sns.set_palette(\"husl\")\n\n",
            "print(f\"âœ… PyTorch version: {torch.__version__}\")\n",
            "print(f\"âœ… CUDA available: {torch.cuda.is_available()}\")\n",
            "print(f\"âœ… Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")"
        ]
    })
    
    # Add all code sections with proper ordering
    sections = [
        ("âš™ï¸ 3. è¨­å®šã‚¯ãƒ©ã‚¹ (Configuration)", "config_", python_files['config.py'], 
         "Configuration classes defined"),
        ("ğŸ¯ 4. ç‰©ç†ã‚¨ãƒ³ã‚¸ãƒ³ (Physics Engine)", "physics_", python_files['physics.py'], 
         "Physics engine implemented"),
        ("ğŸ® 5. è¦³æ¸¬ãƒ»è¡Œå‹•ç©ºé–“ (Observation and Action Spaces)", "spaces_", python_files['spaces.py'], 
         "Observation and action spaces defined"),
        ("ğŸ† 6. å ±é…¬ã‚·ã‚¹ãƒ†ãƒ  (Reward System)", "rewards_", python_files['rewards.py'], 
         "Reward system implemented"),
        ("ğŸ¨ 7. ãƒ¬ãƒ³ãƒ€ãƒ©ãƒ¼ (Renderer)", "renderer_", python_files['renderer.py'], 
         "Renderer implemented"),
        ("ğŸŒ 8. ãƒ¡ã‚¤ãƒ³ç’°å¢ƒ (Main Soccer Environment)", "env_", python_files['soccer_env.py'], 
         "Soccer environment implemented"),
        ("ğŸ¤– 9. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£… (Agents)", "agents_", python_files['agents.py'], 
         "Agents implemented"),
        ("ğŸ“š 10. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ (Training Frameworks)", "trainers_", python_files['trainers.py'], 
         "Training frameworks implemented"),
        ("ğŸ§ª 11. ãƒ†ã‚¹ãƒˆé–¢æ•° (Test Functions)", "test_", python_files['test_environment.py'], 
         "Test functions implemented")
    ]
    
    for title, id_prefix, code, success_msg in sections:
        # Add section header
        notebook['cells'].append({
            "cell_type": "markdown",
            "metadata": {"id": f"{id_prefix}header"},
            "source": [f"## {title}"]
        })
        
        # Add code cell
        notebook['cells'].append({
            "cell_type": "code",
            "metadata": {"id": f"{id_prefix}code"},
            "execution_count": None,
            "outputs": [],
            "source": code + f"\n\nprint(\"âœ… {success_msg} successfully!\")"
        })
    
    # Add execution section
    notebook['cells'].append({
        "cell_type": "markdown",
        "metadata": {"id": "execution_header"},
        "source": [
            "## ğŸš€ 12. å®Ÿè¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³ (Execution Section)\n\n",
            "ä»¥ä¸‹ã®ã‚»ãƒ«ã§ç’°å¢ƒã‚’ãƒ†ã‚¹ãƒˆã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´ã§ãã¾ã™ã€‚\n",
            "**é‡è¦**: ä¸Šè¨˜ã®ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ã‹ã‚‰ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
        ]
    })
    
    # Test environment
    notebook['cells'].append({
        "cell_type": "markdown",
        "metadata": {"id": "test_env_header"},
        "source": ["### 12.1 ç’°å¢ƒãƒ†ã‚¹ãƒˆ"]
    })
    
    notebook['cells'].append({
        "cell_type": "code",
        "metadata": {"id": "test_env"},
        "execution_count": None,
        "outputs": [],
        "source": [
            "# ç’°å¢ƒã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ\n",
            "print(\"ğŸ§ª Running environment tests...\")\n",
            "print(\"=\" * 60)\n\n",
            "test_passed = run_all_tests()\n\n",
            "if test_passed:\n",
            "    print(\"\\nâœ… All environment tests passed! Ready to proceed with training.\")\n",
            "else:\n",
            "    print(\"\\nâŒ Some tests failed. Please check the implementation.\")"
        ]
    })
    
    # Create environment and run baseline
    notebook['cells'].append({
        "cell_type": "markdown",
        "metadata": {"id": "baseline_header"},
        "source": ["### 12.2 ç’°å¢ƒä½œæˆã¨ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"]
    })
    
    notebook['cells'].append({
        "cell_type": "code",
        "metadata": {"id": "baseline_code"},
        "execution_count": None,
        "outputs": [],
        "source": [
            "# ç’°å¢ƒã®ä½œæˆ\n",
            "config = SoccerEnvironmentConfig()\n",
            "env = make_soccer_env(config, render_mode=None, action_type=\"continuous\")\n\n",
            "print(\"ğŸ“Š Environment Configuration:\")\n",
            "print(f\"  Field Size: {config.FIELD_SIZE}\")\n",
            "print(f\"  Max Steps: {config.MAX_STEPS}\")\n",
            "print(f\"  Players per Team: {config.NUM_PLAYERS_PER_TEAM}\")\n",
            "print(f\"  Agents: {env.agents}\")\n",
            "print(f\"  Observation space: {env.observation_spaces[env.agents[0]].shape}\")\n",
            "print(f\"  Action space: {env.action_spaces[env.agents[0]].shape}\")\n\n",
            "# ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ\n",
            "print(\"\\nğŸ² Running baseline with random agents...\")\n",
            "print(\"=\" * 60)\n\n",
            "random_agents = {}\n",
            "for i, agent_name in enumerate(env.agents):\n",
            "    random_agents[agent_name] = RandomAgent(i, action_space_size=5, action_type=\"continuous\")\n\n",
            "# 5ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å®Ÿè¡Œ\n",
            "episode_stats = []\n",
            "for episode in range(5):\n",
            "    env.reset()\n",
            "    episode_reward = {agent: 0 for agent in env.agents}\n",
            "    steps = 0\n",
            "    \n",
            "    while not all(env.terminations.values()) and not all(env.truncations.values()):\n",
            "        for agent in env.agents:\n",
            "            if not env.terminations.get(agent, False) and not env.truncations.get(agent, False):\n",
            "                obs = env.observe(agent)\n",
            "                action = random_agents[agent].select_action(obs, training=False)\n",
            "                env.step(action)\n",
            "                episode_reward[agent] += env.rewards.get(agent, 0)\n",
            "                steps += 1\n",
            "                \n",
            "                if env.terminations.get(agent, False) or env.truncations.get(agent, False):\n",
            "                    break\n",
            "    \n",
            "    print(f\"Episode {episode + 1}: {steps} steps, Scores: {env.scores}, \"\n",
            "          f\"Total Reward: {sum(episode_reward.values()):.2f}\")\n",
            "    \n",
            "    episode_stats.append({\n",
            "        'episode': episode,\n",
            "        'steps': steps,\n",
            "        'scores': env.scores.copy(),\n",
            "        'total_reward': sum(episode_reward.values())\n",
            "    })\n\n",
            "# çµ±è¨ˆè¡¨ç¤º\n",
            "avg_steps = np.mean([stat['steps'] for stat in episode_stats])\n",
            "avg_reward = np.mean([stat['total_reward'] for stat in episode_stats])\n",
            "team_0_wins = sum(1 for stat in episode_stats if stat['scores'][0] > stat['scores'][1])\n",
            "team_1_wins = sum(1 for stat in episode_stats if stat['scores'][1] > stat['scores'][0])\n",
            "draws = len(episode_stats) - team_0_wins - team_1_wins\n\n",
            "print(f\"\\nğŸ“ˆ Baseline Statistics (Random Agents):\")\n",
            "print(f\"  Average Steps per Episode: {avg_steps:.1f}\")\n",
            "print(f\"  Average Total Reward: {avg_reward:.2f}\")\n",
            "print(f\"  Team 0 (Blue) Wins: {team_0_wins}\")\n",
            "print(f\"  Team 1 (Red) Wins: {team_1_wins}\")\n",
            "print(f\"  Draws: {draws}\")"
        ]
    })
    
    # Simple training demo
    notebook['cells'].append({
        "cell_type": "markdown",
        "metadata": {"id": "training_header"},
        "source": ["### 12.3 ç°¡å˜ãªè¨“ç·´ãƒ‡ãƒ¢"]
    })
    
    notebook['cells'].append({
        "cell_type": "code",
        "metadata": {"id": "simple_training"},
        "execution_count": None,
        "outputs": [],
        "source": [
            "# ç°¡å˜ãªè¨“ç·´ãƒ‡ãƒ¢ï¼ˆRandom Agentsã®æ€§èƒ½æ¸¬å®šï¼‰\n",
            "print(\"ğŸ“Š Performance measurement over multiple episodes...\")\n",
            "print(\"=\" * 60)\n\n",
            "num_test_episodes = 20\n",
            "all_rewards = []\n",
            "all_scores = {'team_0': [], 'team_1': []}\n\n",
            "for ep in range(num_test_episodes):\n",
            "    env.reset()\n",
            "    episode_reward = 0\n",
            "    \n",
            "    while not all(env.terminations.values()) and not all(env.truncations.values()):\n",
            "        for agent in env.agents:\n",
            "            if not env.terminations.get(agent, False) and not env.truncations.get(agent, False):\n",
            "                obs = env.observe(agent)\n",
            "                action = random_agents[agent].select_action(obs, training=False)\n",
            "                env.step(action)\n",
            "                episode_reward += env.rewards.get(agent, 0)\n",
            "                \n",
            "                if env.terminations.get(agent, False) or env.truncations.get(agent, False):\n",
            "                    break\n",
            "    \n",
            "    all_rewards.append(episode_reward)\n",
            "    all_scores['team_0'].append(env.scores[0])\n",
            "    all_scores['team_1'].append(env.scores[1])\n",
            "    \n",
            "    if (ep + 1) % 5 == 0:\n",
            "        print(f\"Episodes {ep-3}-{ep+1}: Avg Reward = {np.mean(all_rewards[-5:]):.2f}, \"\n",
            "              f\"Scores = Blue:{np.mean(all_scores['team_0'][-5:]):.1f}, \"\n",
            "              f\"Red:{np.mean(all_scores['team_1'][-5:]):.1f}\")\n\n",
            "# çµæœã®ãƒ—ãƒ­ãƒƒãƒˆ\n",
            "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n\n",
            "# Rewards over time\n",
            "ax1.plot(all_rewards, alpha=0.5)\n",
            "ax1.plot(np.convolve(all_rewards, np.ones(5)/5, mode='valid'), linewidth=2)\n",
            "ax1.set_title('Total Rewards per Episode')\n",
            "ax1.set_xlabel('Episode')\n",
            "ax1.set_ylabel('Total Reward')\n",
            "ax1.grid(True)\n\n",
            "# Team scores\n",
            "ax2.plot(all_scores['team_0'], label='Team 0 (Blue)', alpha=0.7)\n",
            "ax2.plot(all_scores['team_1'], label='Team 1 (Red)', alpha=0.7)\n",
            "ax2.set_title('Team Scores Over Episodes')\n",
            "ax2.set_xlabel('Episode')\n",
            "ax2.set_ylabel('Goals Scored')\n",
            "ax2.legend()\n",
            "ax2.grid(True)\n\n",
            "plt.tight_layout()\n",
            "plt.show()\n\n",
            "print(f\"\\nğŸ“ˆ Final Statistics ({num_test_episodes} episodes):\")\n",
            "print(f\"  Mean Total Reward: {np.mean(all_rewards):.2f} Â± {np.std(all_rewards):.2f}\")\n",
            "print(f\"  Team 0 Mean Score: {np.mean(all_scores['team_0']):.2f} Â± {np.std(all_scores['team_0']):.2f}\")\n",
            "print(f\"  Team 1 Mean Score: {np.mean(all_scores['team_1']):.2f} Â± {np.std(all_scores['team_1']):.2f}\")"
        ]
    })
    
    # Summary
    notebook['cells'].append({
        "cell_type": "markdown",
        "metadata": {"id": "summary"},
        "source": [
            "## ğŸ“ ã¾ã¨ã‚\n\n",
            "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ä»¥ä¸‹ã‚’å®Ÿè£…ã—ã¾ã—ãŸï¼š\n\n",
            "### âœ… å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½\n",
            "1. **å®Œå…¨ãªç‰©ç†ã‚¨ãƒ³ã‚¸ãƒ³**: è¡çªæ¤œå‡ºã€ãƒœãƒ¼ãƒ«ç‰©ç†ã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ç§»å‹•\n",
            "2. **PettingZooäº’æ›ç’°å¢ƒ**: ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¼·åŒ–å­¦ç¿’ã®æ¨™æº–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹\n",
            "3. **è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…**:\n",
            "   - Random Agent (ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³)\n",
            "   - DQN Agent (ç‹¬ç«‹å­¦ç¿’)\n",
            "   - MADDPG Agent (å”èª¿å­¦ç¿’)\n",
            "4. **è±Šå¯Œãªè¦³æ¸¬ç©ºé–“**: 28æ¬¡å…ƒã®è¦³æ¸¬ï¼ˆä½ç½®ã€é€Ÿåº¦ã€ã‚²ãƒ¼ãƒ çŠ¶æ…‹ï¼‰\n",
            "5. **å¤šç›®çš„å ±é…¬ã‚·ã‚¹ãƒ†ãƒ **: ã‚´ãƒ¼ãƒ«ã€ãƒœãƒ¼ãƒ«åˆ¶å¾¡ã€ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯\n",
            "6. **è¨“ç·´ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: ç‹¬ç«‹å­¦ç¿’ã¨MADDPG\n\n",
            "### ğŸš€ ä½¿ç”¨æ–¹æ³•\n",
            "1. **ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ã‚»ãƒ«ã‚’ä¸Šã‹ã‚‰é †ç•ªã«å®Ÿè¡Œ**\n",
            "2. ç’°å¢ƒãƒ†ã‚¹ãƒˆã§å‹•ä½œç¢ºèª\n",
            "3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã§åŸºæœ¬æ€§èƒ½ã‚’ç¢ºèª\n",
            "4. å¿…è¦ã«å¿œã˜ã¦è¨“ç·´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´\n\n",
            "### âš ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°\n",
            "- **ModuleNotFoundError**: ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ãŸã‹ç¢ºèª\n",
            "- **NameError**: ã‚»ãƒ«ã®å®Ÿè¡Œé †åºã‚’ç¢ºèªï¼ˆä¸Šã‹ã‚‰é †ç•ªã«ï¼‰\n",
            "- **GPUé–¢é€£ã‚¨ãƒ©ãƒ¼**: Runtime â†’ Change runtime type â†’ GPU\n\n",
            "### ğŸ“š å‚è€ƒæ–‡çŒ®\n",
            "- [PettingZoo Documentation](https://pettingzoo.farama.org/)\n",
            "- [MADDPG Paper](https://arxiv.org/abs/1706.02275)\n",
            "- [DQN Paper](https://arxiv.org/abs/1312.5602)\n\n",
            "**Happy Training! ğŸ®**"
        ]
    })
    
    return notebook

# Create and save the fixed notebook
if __name__ == "__main__":
    notebook = create_fixed_integrated_notebook()
    
    # Save the notebook
    with open("/home/user/webapp/multiagents_soccer_colab_fixed.ipynb", "w", encoding="utf-8") as f:
        json.dump(notebook, f, indent=2, ensure_ascii=False)
    
    print("âœ… Fixed integrated notebook created successfully!")
    print("ğŸ“ Saved as: multiagents_soccer_colab_fixed.ipynb")
    print("\nğŸ“‹ ä¸»ãªä¿®æ­£å†…å®¹:")
    print("  1. å†…éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®importæ–‡ã‚’å‰Šé™¤")
    print("  2. ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ãŒè‡ªå·±å®Œçµå‹ã«")
    print("  3. å®Ÿè¡Œé †åºã®æ˜ç¢ºåŒ–")
    print("  4. ã‚¨ãƒ©ãƒ¼é˜²æ­¢ã®ãŸã‚ã®æ³¨æ„äº‹é …è¿½åŠ ")